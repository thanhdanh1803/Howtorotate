{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"video_process.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+MQI7zaaWoCqfO7guy/lg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"03949e2eee9d4137b7246d4de1877cd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c3f240fd9df542aab515ee8088414c48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1f81fdfa9970461e872211994fd49ab0","IPY_MODEL_2147dd0ddd334d23b2cb769bafd0b7c6"]}},"c3f240fd9df542aab515ee8088414c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f81fdfa9970461e872211994fd49ab0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_05f7fce6fb764b6192553486930a42b2","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":654,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":654,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a811c5290ef242888a79153d3bc94439"}},"2147dd0ddd334d23b2cb769bafd0b7c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_97a9f862f29844ccbf5616f3e436c497","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 654/654 [00:22&lt;00:00, 28.58it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc57eef62d01405181e44421643412c1"}},"05f7fce6fb764b6192553486930a42b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a811c5290ef242888a79153d3bc94439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97a9f862f29844ccbf5616f3e436c497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cc57eef62d01405181e44421643412c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z9QfUCw6w2IV"},"source":["# All codes below had been done in 2 hacking days"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lc2AHfirzDKP","executionInfo":{"status":"ok","timestamp":1605969596560,"user_tz":-420,"elapsed":21733,"user":{"displayName":"Danh Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-o7wGwkrae77DKxi7Vepk6KDYPCQKCghz8IPZ=s64","userId":"01024479301744765870"}},"outputId":"560bb6df-65f0-4670-83d1-aebd7b650cc2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJ8bE-HYzQa3"},"source":["root_dir = '/content/gdrive/My Drive/sprayer_robot/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsVJunC7zeiO","executionInfo":{"status":"ok","timestamp":1605969596562,"user_tz":-420,"elapsed":8795,"user":{"displayName":"Danh Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-o7wGwkrae77DKxi7Vepk6KDYPCQKCghz8IPZ=s64","userId":"01024479301744765870"}},"outputId":"7206e597-5afe-4f41-925c-f808503855d5"},"source":["%cd {root_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/sprayer_robot\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WdgB3zx3zfqe","executionInfo":{"status":"ok","timestamp":1605970546861,"user_tz":-420,"elapsed":958922,"user":{"displayName":"Danh Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-o7wGwkrae77DKxi7Vepk6KDYPCQKCghz8IPZ=s64","userId":"01024479301744765870"}},"outputId":"92f40463-f486-47ff-d133-40bbd3616f5c"},"source":["%cd models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install ."],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/sprayer_robot/models/research\n","Processing /content/gdrive/My Drive/sprayer_robot/models/research\n","Collecting avro-python3\n","  Downloading https://files.pythonhosted.org/packages/b2/5a/819537be46d65a01f8b8c6046ed05603fb9ef88c663b8cca840263788d58/avro-python3-1.10.0.tar.gz\n","Collecting apache-beam\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/3f/93816e989e8e59b337f22927778494a99b2a3e78a3b6a9e34d043c6fab4e/apache_beam-2.25.0-cp36-cp36m-manylinux2010_x86_64.whl (8.7MB)\n","\u001b[K     |████████████████████████████████| 8.7MB 7.2MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n","\u001b[K     |████████████████████████████████| 358kB 40.9MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.4)\n","Collecting tf-models-official\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/33/91e5e90e3e96292717245d3fe87eb3b35b07c8a2113f2da7f482040facdb/tf_models_official-2.3.0-py2.py3-none-any.whl (840kB)\n","\u001b[K     |████████████████████████████████| 849kB 43.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.18.5)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n","Collecting mock<3.0.0,>=1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n","\u001b[?25hCollecting pyarrow<0.18.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/3f/6cac1714fff444664603f92cb9fbe91c7ae25375880158b9e9691c4584c8/pyarrow-0.17.1-cp36-cp36m-manylinux2014_x86_64.whl (63.8MB)\n","\u001b[K     |████████████████████████████████| 63.8MB 47kB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.0)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n","Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.33.2)\n","Collecting fastavro<2,>=0.21.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/a9/473ef678c8862d74c63e11d14afbdbeabe67f92fedd82405de5337d7e6de/fastavro-1.2.0-cp36-cp36m-manylinux2014_x86_64.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 36.2MB/s \n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n","\u001b[K     |████████████████████████████████| 153kB 45.7MB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting future<1.0.0,>=0.18.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n","\u001b[K     |████████████████████████████████| 829kB 32.5MB/s \n","\u001b[?25hRequirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n","Collecting requests<3.0.0,>=2.24.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/fc/f91eac5a39a65f75a7adb58eac7fa78871ea9872283fb9c44e6545998134/requests-2.25.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n","Collecting hdfs<3.0.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (50.3.2)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Collecting tensorflow-model-optimization>=0.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n","\u001b[K     |████████████████████████████████| 174kB 41.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n","Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.9)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n","Collecting opencv-python-headless\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/e9/57d869561389884136be65a2d1bc038fe50171e2ba348fda269a4aab8032/opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7MB)\n","\u001b[K     |████████████████████████████████| 36.7MB 82kB/s \n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n","\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n","\u001b[?25hCollecting pbr>=0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n","\u001b[K     |████████████████████████████████| 112kB 44.0MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.6.20)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->tf-models-official->object-detection==0.1) (0.1.5)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.35.1)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.10.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.3.3)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (0.0.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.2.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.24.0)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (0.4.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.3.3)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.3.0->tf-models-official->object-detection==0.1) (3.1.0)\n","Building wheels for collected packages: object-detection, avro-python3, dill, future, hdfs, py-cpuinfo\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1599251 sha256=cad2cb429e965f3ba4fad8e49d69aeb0aa2e6f8aa9adf991d2dd65f622da625c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r7r3mz9v/wheels/d7/c2/f8/dd4d4d17be7858f1302b15cc70f2d85ca55495b55592ff3c98\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.0-cp36-none-any.whl size=43735 sha256=be852ce9d1797e3fb66c59bcb0ea9283c70924da2b6fceb64c73799e469a91f1\n","  Stored in directory: /root/.cache/pip/wheels/3f/15/cd/fe4ec8b88c130393464703ee8111e2cddebdc40e1b59ea85e9\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78532 sha256=fae40d29f122beb67ad80a4d43ea690ca6872e68a7e51bea372bdc60a9d2104b\n","  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=d63b6cdc8b3e61265b6ca8973bb4b3395587e4d37cad2d8db3169310e32671ea\n","  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n","  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33213 sha256=11a1f3adfe5b296ce03a2d13044c7baace1fac4156ed3de169494a5e7879bec6\n","  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20071 sha256=5dcbcbcbd3fba19b444cb08792b06d3f7418f5ef6447ab5cdf53fff99d494224\n","  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n","Successfully built object-detection avro-python3 dill future hdfs py-cpuinfo\n","\u001b[31mERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: apache-beam 2.25.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\", but you'll have avro-python3 1.10.0 which is incompatible.\u001b[0m\n","Installing collected packages: avro-python3, pbr, mock, pyarrow, fastavro, dill, future, requests, hdfs, apache-beam, tf-slim, lvis, tensorflow-model-optimization, sentencepiece, opencv-python-headless, py-cpuinfo, tf-models-official, object-detection\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","  Found existing installation: dill 0.3.3\n","    Uninstalling dill-0.3.3:\n","      Successfully uninstalled dill-0.3.3\n","  Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","Successfully installed apache-beam-2.25.0 avro-python3-1.10.0 dill-0.3.1.1 fastavro-1.2.0 future-0.18.2 hdfs-2.5.8 lvis-0.5.3 mock-2.0.0 object-detection-0.1 opencv-python-headless-4.4.0.46 pbr-5.5.1 py-cpuinfo-7.0.0 pyarrow-0.17.1 requests-2.25.0 sentencepiece-0.1.94 tensorflow-model-optimization-0.5.0 tf-models-official-2.3.0 tf-slim-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8mO1M0DpziYW"},"source":["import cv2\n","from PIL import Image, ImageDraw, ImageFont\n","import numpy as np\n","import tensorflow as tf\n","import glob\n","import os\n","import io\n","import scipy.misc\n","from six import BytesIO\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZ8L6lRZ1QIY"},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYJKGq_C1cQ2"},"source":["#recover our saved model\n","pipeline_config = '/content/gdrive/My Drive/sprayer_robot/deploy/efficientDet_d3/pipeline_file.config'\n","#generally you want to put the last ckpt from training in here\n","model_dir = '/content/gdrive/My Drive/sprayer_robot/deploy/training/ckpt-2'\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","detection_model = model_builder.build(\n","      model_config=model_config, is_training=False)\n","\n","# Restore checkpoint\n","ckpt = tf.compat.v2.train.Checkpoint(\n","      model=detection_model)\n","ckpt.restore(os.path.join('/content/gdrive/My Drive/sprayer_robot/deploy/training/ckpt-2'))\n","\n","\n","def get_model_detection_function(model):\n","  \"\"\"Get a tf.function for detection.\"\"\"\n","\n","  @tf.function\n","  def detect_fn(image):\n","    \"\"\"Detect objects in image.\"\"\"\n","\n","    image, shapes = model.preprocess(image)\n","    prediction_dict = model.predict(image, shapes)\n","    detections = model.postprocess(prediction_dict, shapes)\n","\n","    return detections, prediction_dict, tf.reshape(shapes, [-1])\n","\n","  return detect_fn\n","\n","detect_fn = get_model_detection_function(detection_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HQEf0jw81f1-","executionInfo":{"status":"ok","timestamp":1605970575108,"user_tz":-420,"elapsed":986429,"user":{"displayName":"Danh Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-o7wGwkrae77DKxi7Vepk6KDYPCQKCghz8IPZ=s64","userId":"01024479301744765870"}},"outputId":"8de35fed-5c64-4f3b-8467-41973b6f849a"},"source":["%cd {root_dir}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/sprayer_robot\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6adXxACs13Be"},"source":["#map labels for inference decoding\n","label_map_path = configs['eval_input_config'].label_map_path\n","label_map = label_map_util.load_labelmap(label_map_path)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map,\n","    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n","    use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gr0k7ntDodx"},"source":["def get_bboxes(full_bboxes, full_scores, im_width, im_height, threshold = 0.5):\n","  bboxes = []\n","  for i in range(len(full_bboxes)):\n","    if full_scores[i] > threshold:\n","      y_min, x_min, y_max, x_max =  full_bboxes[i].tolist()\n","      (y_min, x_min, y_max, x_max) = (y_min * im_height, x_min * im_width, \\\n","                                    y_max * im_height, x_max * im_width)\n","      bboxes.append((y_min, x_min, y_max, x_max))\n","  bboxes = np.array(bboxes)\n","  bboxes = bboxes.astype('int')\n","  return bboxes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["03949e2eee9d4137b7246d4de1877cd0","c3f240fd9df542aab515ee8088414c48","1f81fdfa9970461e872211994fd49ab0","2147dd0ddd334d23b2cb769bafd0b7c6","05f7fce6fb764b6192553486930a42b2","a811c5290ef242888a79153d3bc94439","97a9f862f29844ccbf5616f3e436c497","cc57eef62d01405181e44421643412c1"]},"id":"beQfrgmH14Qm","executionInfo":{"status":"ok","timestamp":1605971519408,"user_tz":-420,"elapsed":25398,"user":{"displayName":"Danh Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-o7wGwkrae77DKxi7Vepk6KDYPCQKCghz8IPZ=s64","userId":"01024479301744765870"}},"outputId":"52edbb90-c043-4183-a3c5-229bbb40fd74"},"source":["#run detector on test image\n","#it takes a little longer on the first run and then runs at normal speed. \n","video_dir = os.path.join(root_dir, 'videos')\n","video_name = glob.glob(video_dir+'/*.mp4')[1]\n","output_dir = os.path.join(root_dir, 'output_videos')\n","output_name = os.path.join(output_dir, video_name.split('/')[-1].split('.')[0]) + '.avi'\n","writer = None\n","print('INFO: Read video file')\n","print('INFO: Output file name:', output_name)\n","vs = cv2.VideoCapture(video_name)\n","fps = vs.get(cv2.CAP_PROP_FPS)\n","width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","print('INFO: Video (W,H, FPS)', (width, height, fps))\n","max_frame = int(vs.get(cv2.CAP_PROP_FRAME_COUNT))\n","frame_id = 0\n","for i in tqdm(range(max_frame)):\n","  #read the next frame from file\n","  (grabbed, frame) = vs.read()\n","  if not grabbed:\n","    print('[INFO] Video '+ video_name +' Compeleted!!!')\n","    break\n","  try:\n","    frame_id += 1\n","    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    #print(frame.shape)\n","  except Exception as e:\n","    print(e)\n","    break\n","  if i % (fps//10) == 0:\n","    #make prediction\n","    input_tensor = tf.convert_to_tensor(\n","        np.expand_dims(frame, 0), dtype=tf.float32)\n","    detections, predictions_dict, shapes = detect_fn(input_tensor)\n","\n","    label_id_offset = 1\n","    image_np_with_detections = frame.copy()\n","    #nms\n","    nms_boxes = tf.image.non_max_suppression(detections['detection_boxes'][0], detections['detection_scores'][0],4, iou_threshold=0.3)\n","    nms_boxes = nms_boxes.numpy()\n","\n","    bboxes = get_bboxes(detections['detection_boxes'][0].numpy()[nms_boxes],\n","                        detections['detection_scores'][0].numpy()[nms_boxes],\n","                        width, height,\n","                        threshold=0.4)\n","    cv2.line(image_np_with_detections, (width//2, 0), (width//2, height), (255, 0, 0), 5)\n","    cv2.line(image_np_with_detections, (0, height//4), (width, height//4), (0, 255, 0), 5)\n","    cv2.line(image_np_with_detections, (0, 3*height//4), (width, 3*height//4), (0, 255, 0), 5)\n","    text_top = 'OFF'\n","    text_bot = 'OFF'\n","    for box in bboxes:\n","      top_left = (box[1], box[0])\n","      top_right = (box[3], box[0])\n","      bot_left = (box[1], box[2])\n","      bot_right = (box[3], box[2])\n","      if top_left[0] < width//2 and top_right[0] > width//2 \\\n","      and top_left[1] < height//4:\n","        text_top = 'ON'\n","      if bot_left[0] < width//2 and bot_right[0] > width//2 and bot_left[1] > 3 * width//4:\n","        text_bot = 'ON'\n","      cv2.rectangle(image_np_with_detections, (box[1], box[0]), (box[3], box[2]), (0, 0, 255), 3)\n","    #On or Off sprayer\n","    cv2.putText(image_np_with_detections, text_top, (0,300), cv2.FONT_HERSHEY_SIMPLEX,\t3, (255, 0 ,0), 7)\n","    cv2.putText(image_np_with_detections, text_bot, (0, height-200), cv2.FONT_HERSHEY_SIMPLEX,\t3, (255, 0 ,0), 7)\n","    #save video\n","    if writer is None:\n","      fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n","      writer = cv2.VideoWriter(output_name, fourcc, 10, (image_np_with_detections.shape[1], image_np_with_detections.shape[0]), True)\n","    if writer is not None:\n","      image_np_with_detections = cv2.cvtColor(image_np_with_detections, cv2.COLOR_RGB2BGR)\n","      writer.write(image_np_with_detections)\n","writer.release()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO: Read video file\n","INFO: Output file name: /content/gdrive/My Drive/sprayer_robot/output_videos/video2.avi\n","INFO: Video (W,H, FPS) (1080, 1920, 60.0)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03949e2eee9d4137b7246d4de1877cd0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=654.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Us6k8zLOYQm"},"source":[""],"execution_count":null,"outputs":[]}]}